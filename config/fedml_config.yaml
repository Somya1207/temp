common_args:
  training_type: "simulation"
  random_seed: 0
  config_version: "dev"
  mlops_api_key: c9356b9c4ce44363bb66366b210201
  mlops_project_name: simulation_2
  mlops_run_name: fedml_torch_fedavg_mnist_lr_1
  scenario_name: "main"
data_args:
  dataset: "femnist_x"
  data_cache_dir: ~/.cache/fedml_data
  partition_method: "hetero"
  partition_alpha: 0.3
  psi_eval_max_no_progress: 10
  psi_eval_burn_in: 30
  # psi_eval_burn_in: 2
model_args:
  model: "lr"

train_args:
  federated_optimizer: "FedAvg"
  client_id_list: "[]"
  client_num_in_total: 100
  client_num_per_round: 10
  comm_round: 100 # 3 is for quick GitHub sanity check. please change this to your own hyper-parameters (e.g., 200)
  # comm_round: 5
  epochs: 2
  epochs_model_selection: 2000
  # epochs_model_selection: 15
  batch_size: 200
  client_optimizer: sgd
  learning_rate: 0.01
  # learning_rate: 0.01
  fedprox_mu : 0.01
  weight_decay: 0.001
  learning_rate_decay_gamma: 0.5

validation_args:
  frequency_of_the_test: 20
  # frequency_of_the_test: 2
  print_freq: 100
  # print_freq: 2
  verbose: True
  # print_freq_mul: 5
  print_freq_mul: 1
  burn_in: 30
  # burn_in: 5
  max_no_progress: 10
  # eval_freq: 20
  eval_freq: 1 
  video_plotter: False

device_args:
  using_gpu: True
  gpu_id: 2

comm_args:
  backend: "sp"

tracking_args:
  enable_tracking: false
   # When running on MLOps platform(open.fedml.ai), the default log path is at ~/.fedml/fedml-client/fedml/logs/ and ~/.fedml/fedml-server/fedml/logs/
  # enable_wandb: True
  # wandb_key: 3707945e4c94eb3321cc407ff126f7ed4215db82
  # wandb_entity: somya23005
  # wandb_project: fedgmm
  run_name: comm_round-350_local_2_step_fedAvg_sgd
  using_mlops: false

